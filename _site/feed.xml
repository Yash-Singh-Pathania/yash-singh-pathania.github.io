<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-09-13T17:21:15+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Hii There</title><subtitle>Hey there! I‚Äôm Yash, a Ruby and Python developer with a knack for AWS, diving into computer vision, and pioneering AR/VR. I love blending tech with a dash of sci-fi, turning futuristic dreams into reality. From backend architectures to immersive AR experiences, I‚Äôm all about exploring new dimensions of code and pushing the boundaries of what‚Äôs possible.</subtitle><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><entry><title type="html">Bruno</title><link href="http://localhost:4000/posts/bruno/" rel="alternate" type="text/html" title="Bruno" /><published>2024-09-03T00:00:00+01:00</published><updated>2024-09-03T00:00:00+01:00</updated><id>http://localhost:4000/posts/Bruno</id><content type="html" xml:base="http://localhost:4000/posts/bruno/"><![CDATA[<p>APIs are crucial today, but testing tools  inlcuding dev testing especially between devs is a hassle. The most popular tool, Postman, has become bloated, with many features hidden behind a paywall. This led me on a search for an open-source, privacy-focused API testing tool‚Äî<strong>Bruno</strong>.</p>

<h2 id="why-bruno-">Why Bruno? ü§î</h2>

<p>Bruno lets users store collections and API requests, traditionally kept in Postman, but with a more streamlined, Git-friendly approach. This eliminates the confusion of having API requests versioned separately from your code, making it easier to share cURL requests across teams like QA, product, and other stakeholders.</p>

<p><img src="https://miro.medium.com/v2/resize:fit:1228/1*CHz8MRsvJXszYsUTehVZkQ.png" alt="Bruno Logo" /></p>

<h3 id="personal-story-time-">Personal Story Time! üìñ</h3>

<p>Let me tell you about the time I first tried Bruno. I was working on a hackathon project at an internal event at <a href="https://www.1mg.com">1mg</a>, and the APIs were a tangled mess. Our team struggled with complex collections and bloated workspaces. Then, I found Bruno. It felt like discovering a secret weapon. Suddenly, APIs were fun again! I could clone a repo, see real examples, and get to work immediately. No more ‚ÄúWhere‚Äôs that JSON file?‚Äù moments. üí°</p>

<h2 id="bruno-vs-other-api-tools-">Bruno vs. Other API Tools üîç</h2>
<h3 id="key-benefits">Key Benefits:</h3>
<ul>
  <li>
    <p><strong>Lightweight &amp; User-Friendly Interface</strong>: Bruno‚Äôs snappy UI is built with Electron and available on all major desktop platforms‚ÄîLinux, Mac, and Windows. Unlike Postman, Bruno is entirely offline, ensuring your data stays on your machine.</p>
  </li>
  <li>
    <p><strong>Privacy First</strong>: Unlike Postman, which routes API requests through proprietary proxy servers, Bruno handles requests directly from your computer, keeping your data private and secure.</p>
  </li>
  <li>
    <p><strong>Git Integration</strong>: Bruno uses a plain text markup language called Bru, storing API requests directly in your repository. This allows seamless version control and collaboration using tools like Git.</p>
  </li>
</ul>

<h3 id="additional-features">Additional Features:</h3>
<ul>
  <li><strong>No Paywall</strong>: Bruno is a FOSS project with no hidden fees, unlike Postman, which locks essential features behind a paywall.</li>
  <li><strong>Unlimited Collection Runs</strong>: Postman limits collection runs, but with Bruno, you can run collections as many times as you like.</li>
  <li><strong>Secret Management</strong>: Load secrets directly from a <code class="language-plaintext highlighter-rouge">.env</code> file, eliminating the need to manage them separately.</li>
  <li><strong>Declarative Scripting</strong>: Write tests and update post-response variables using simple expressions, supported by Bruno‚Äôs declarative scripting features.</li>
  <li><strong>CLI Support</strong>: Run API collections with ease using Bruno‚Äôs CLI, integrating smoothly with your CI/CD workflows.</li>
</ul>

<h3 id="the-future-of-api-testing-Ô∏è">The Future of API Testing üõ†Ô∏è</h3>

<p>Bruno is revolutionizing API testing by focusing on privacy, efficiency, and user control. By co-locating API collections with your source code and enabling Git management, Bruno offers a cohesive and secure solution for developers and teams.</p>]]></content><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><category term="CodingTools" /><summary type="html"><![CDATA[APIs are crucial today, but testing tools inlcuding dev testing especially between devs is a hassle. The most popular tool, Postman, has become bloated, with many features hidden behind a paywall. This led me on a search for an open-source, privacy-focused API testing tool‚ÄîBruno.]]></summary></entry><entry><title type="html">Hawkeye : Computer Vision For Metrics [WIP]</title><link href="http://localhost:4000/posts/building_hawkeye/" rel="alternate" type="text/html" title="Hawkeye : Computer Vision For Metrics [WIP]" /><published>2024-08-14T00:00:00+01:00</published><updated>2024-08-14T00:00:00+01:00</updated><id>http://localhost:4000/posts/building_hawkeye</id><content type="html" xml:base="http://localhost:4000/posts/building_hawkeye/"><![CDATA[<p>As the lead developer at Tata 1mg, designing the Common Order Taking (COT) portal, I realized the critical need for analytics and performance metrics in high-efficiency retail stores, dark stores, and warehouses. When every last rupee counts towards profitability, understanding these metrics is imperative. So during my notice period i have decided to work on something called hawkeye ( i watch cricket a lot and hence the name )</p>

<h2 id="introducing-hawk-eye">Introducing HaWk Eye</h2>

<p>The idea of HaWk Eye (yes, I wanted to spell it with a capital H and W) was born from this need. I envision it as a computer vision software that can evolve into a great SaaS product. It has the potential to be specialized for very specific use cases like warehouses and retail stores.</p>

<h2 id="what-to-expect">What to Expect</h2>

<p>I‚Äôll keep updating this blog with my progress on HaWk Eye, detailing what I‚Äôm doing and how I‚Äôm going about it. For anyone reading this, I aim to keep everything organized in one specific folder. This page will serve as the root for all future updates.</p>

<p>As I pen down this header, I am excited and eager to code. Happy reading!</p>

<h2 id="progress">Progress</h2>
<p>-<a href="../building_hawkeye/week1">Week 1: Core Functionality Development</a></p>]]></content><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><category term="Computer Vision" /><category term="Python" /><summary type="html"><![CDATA[As the lead developer at Tata 1mg, designing the Common Order Taking (COT) portal, I realized the critical need for analytics and performance metrics in high-efficiency retail stores, dark stores, and warehouses. When every last rupee counts towards profitability, understanding these metrics is imperative. So during my notice period i have decided to work on something called hawkeye ( i watch cricket a lot and hence the name )]]></summary></entry><entry><title type="html">Week 1: Core Functionality Development</title><link href="http://localhost:4000/posts/building_hawkeye/week1/" rel="alternate" type="text/html" title="Week 1: Core Functionality Development" /><published>2024-07-14T00:00:00+01:00</published><updated>2024-07-14T00:00:00+01:00</updated><id>http://localhost:4000/posts/building_hawkeye/week1</id><content type="html" xml:base="http://localhost:4000/posts/building_hawkeye/week1/"><![CDATA[<p>Day 1-7: Project Setup and Initial Development</p>

<h2 id="day-1-setting-up-hawkeye">Day 1: Setting Up Hawkeye</h2>

<p><em>13 July 2024</em>
Hey everyone, on day one my basic aim is to research what I am going to pen down, jot down my feelings, and think about this. I am thinking of using FastAPI for the backend because I have never used it before, and I consider it should not be too heavy when it comes to backend development.</p>

<h3 id="frameworks-and-tools">Frameworks and Tools</h3>
<ul>
  <li>Backend: FastAPI for the API</li>
  <li>Frontend: Streamlit (I chose Streamlit because it looks good, and for an MVP, I believe frontend aesthetics are not critical. We can focus on backend functionality and scale up to something more robust and visually appealing later on.)</li>
  <li>Database: PostgreSQL or SQLite for storing video data and analysis results (I prefer PostgreSQL due to my familiarity with the Tortoise wrapper, which should facilitate better interaction. I still need to finalize the database design.)</li>
  <li>Cloud Storage: AWS S3 (I can set up a local stack to mirror AWS S3)</li>
  <li>Deployment: Docker for containerization, AWS EC2 (local stack supremacy)</li>
</ul>

<p>Today, I made progress by setting up my GitHub repository, pushing my requirements, and establishing a basic file structure. I faced some challenges because I just bought a new MacBook Pro M3, so I had to install Python and everything from scratch, but it was fairly easy. I‚Äôve also created a <code class="language-plaintext highlighter-rouge">requirements.txt</code> that will help in setting up and Dockerizing later. My next steps involve setting up the basic application.</p>

<h2 id="github-repo-link-hawkeye-github-repo">GitHub repo link: <a href="https://github.com/yash-singh-pathania/Hawkeye">Hawkeye GitHub Repo</a></h2>

<h2 id="day-2-trying-my-hand-on-detection">Day 2: Trying My Hand On Detection</h2>

<p><em>14 July 2024</em>
This was day 2 of the project, and I was weirdly excited about it. I had to decide whether to try detecting people and tracking them or do other things that would make my life better in the long run, like setting up pre-commit hooks, maybe setting up a linter, and so on. But being a developer at heart, I went the detection route and set up basic detection for people and tracking them across the retail floor.</p>

<p>I am still looking for some model that does this better because right now I find myself stuck on how to make this MVP. My idea is simple:</p>

<p>If I can process a pre-recorded video in 80% of the time of the full video‚Äîsay if the video is 10 minutes and I can process it in 8 minutes‚ÄîI should be able to do this virtually live, which is my aim in the long run. Right now, I am having difficulties setting up Streamlit, sending it the tracking data and the video, and putting it all together. I think I‚Äôll do it together; let‚Äôs see.</p>

<p>Today‚Äôs commit <a href="https://github.com/Yash-Git-Hub/Hawkeye/compare/481a8eb6e00e15b6cb6493122557534439894e95...cf40098133a17c5438040cadca662e35221db8e7">commit</a></p>

<hr />]]></content><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><category term="Computer Vision" /><category term="Python" /><category term="Building Hawkeye" /><summary type="html"><![CDATA[Day 1-7: Project Setup and Initial Development]]></summary></entry><entry><title type="html">Leet Code Subpage 2</title><link href="http://localhost:4000/posts/leetcode/subpage2/" rel="alternate" type="text/html" title="Leet Code Subpage 2" /><published>2024-07-14T00:00:00+01:00</published><updated>2024-07-14T00:00:00+01:00</updated><id>http://localhost:4000/posts/leetcode/subpage2</id><content type="html" xml:base="http://localhost:4000/posts/leetcode/subpage2/"><![CDATA[<p>This is the second subpage for the LeetCode Fun Questions blog post. Here, I will cover more advanced problems and techniques.</p>]]></content><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><category term="leetcode" /><summary type="html"><![CDATA[This is the second subpage for the LeetCode Fun Questions blog post. Here, I will cover more advanced problems and techniques.]]></summary></entry><entry><title type="html">Leet Code Fun Questions</title><link href="http://localhost:4000/posts/leetcode/" rel="alternate" type="text/html" title="Leet Code Fun Questions" /><published>2024-07-14T00:00:00+01:00</published><updated>2024-07-14T00:00:00+01:00</updated><id>http://localhost:4000/posts/leetcode</id><content type="html" xml:base="http://localhost:4000/posts/leetcode/"><![CDATA[<p>This is the place where I write about the LeetCode questions I find interesting. I rarely do LeetCode, but I need to brush up on my DSA and competitive coding skills before my master‚Äôs, so I‚Äôll be blogging about that here.</p>

<p>Check out these subpages for more detailed discussions:</p>
<ul>
  <li><a href="../leetcode/1518">Bottle Exchange</a></li>
  <li><a href="../leetcode/subpage2">Subpage 2</a></li>
</ul>]]></content><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><category term="Leetcode" /><category term="Competitive Coding" /><summary type="html"><![CDATA[This is the place where I write about the LeetCode questions I find interesting. I rarely do LeetCode, but I need to brush up on my DSA and competitive coding skills before my master‚Äôs, so I‚Äôll be blogging about that here.]]></summary></entry><entry><title type="html">Moving From ruby 2.6 -&amp;gt; Ruby 3.2 Yjit</title><link href="http://localhost:4000/posts/yjit_upgrade" rel="alternate" type="text/html" title="Moving From ruby 2.6 -&amp;gt; Ruby 3.2 Yjit" /><published>2024-04-07T00:00:00+01:00</published><updated>2024-04-07T00:00:00+01:00</updated><id>http://localhost:4000/posts/yjit</id><content type="html" xml:base="http://localhost:4000/posts/yjit_upgrade"><![CDATA[<h1 id="upgrading-ruby-and-rails-to-yjit-a-deep-dive-into-breaking-changes-challenges-and-code-improvements">Upgrading Ruby and Rails to YJIT: A Deep Dive into Breaking Changes, Challenges, and Code Improvements</h1>

<p><em>Date: September 13, 2024</em></p>

<p>When we decided to upgrade our Ruby and Rails stack at work, it was clear that the journey would not be without its hurdles. Moving from <strong>Ruby 2.6.2</strong> to <strong>Ruby 3.2</strong> and <strong>Rails 5.1.4</strong> to <strong>Rails 7.0.6</strong> required not just simple version bumps but a thorough understanding of how breaking changes would impact our codebase. Add in the transition to <strong>YJIT</strong> (Ruby‚Äôs new Just-In-Time compiler), and we had quite the challenge ahead of us. In this blog, I‚Äôll walk you through the journey, the breaking changes we encountered, and how we overcame them with concrete examples and code snippets.</p>

<h2 id="why-the-upgrade">Why the Upgrade?</h2>

<p>The main reason for upgrading was that our current Ruby and Rails versions had reached their end-of-life (EOL). <strong>Ruby 2.6</strong> was no longer receiving security patches or updates, and Rails 5.1.4, while functional, had several inefficiencies that Rails 7 has since addressed. The introduction of <strong>YJIT</strong> in Ruby 3.1 promised substantial performance gains, and we were eager to see how that would play out in production.</p>

<h2 id="breaking-down-the-version-upgrade-process">Breaking Down the Version Upgrade Process</h2>

<h3 id="the-two-branch-problem">The Two-Branch Problem</h3>

<p>Before upgrading, we had two branches in play: one for <strong>Ruby 2.6 (CRuby)</strong> and one for <strong>JRuby</strong>. Maintaining these two branches was crucial for us because <strong>JRuby</strong> provided the necessary multithreading performance for certain high-concurrency operations, while <strong>CRuby</strong> handled the bulk of our application logic.</p>

<h4 id="why-we-maintained-two-branches">Why We Maintained Two Branches</h4>

<ul>
  <li><strong>JRuby</strong> was essential for running background jobs and handling high-concurrency workloads.</li>
  <li><strong>CRuby (Ruby 2.6)</strong> provided better day-to-day performance for core application functionality.</li>
</ul>

<p>However, this setup came with a cost. Each new feature or fix required deployment to <strong>both</strong> branches, resulting in additional complexity and time. Merging changes across these branches was tedious, often leading to deployment delays.</p>

<h3 id="enter-ruby-32-and-yjit">Enter Ruby 3.2 and YJIT</h3>

<p>The introduction of <strong>YJIT</strong> in Ruby 3.1 was a game-changer. <strong>YJIT</strong> compiled Ruby code just-in-time, delivering a significant performance boost without requiring a complete overhaul of our JRuby setup. With YJIT, we could effectively <strong>merge</strong> both branches back into a single <strong>Ruby 3.2</strong> branch and still retain the performance benefits we had been leveraging from JRuby.</p>

<h3 id="pre-upgrade-deployment-with-two-branches">Pre-Upgrade Deployment with Two Branches</h3>

<p>Before the upgrade, we had to maintain <strong>two branches</strong> for deployment:</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">main</code> branch (for <strong>CRuby 2.6</strong>)</li>
  <li><code class="language-plaintext highlighter-rouge">jruby_main</code> branch (for <strong>JRuby</strong>)</li>
</ol>

<p>Each branch had its own set of gem versions and <code class="language-plaintext highlighter-rouge">Gemfile.lock</code>. This setup was challenging because any change made to the <code class="language-plaintext highlighter-rouge">main</code> branch needed to be merged into the <code class="language-plaintext highlighter-rouge">jruby_main</code> branch. This often resulted in <strong>conflicts</strong>, especially in the <strong>Gemfile.lock</strong> file.</p>

<h4 id="pre-upgrade-deployment-flow">Pre-Upgrade Deployment Flow</h4>

<p>Here‚Äôs how the deployment process used to work:</p>

<ul>
  <li>Make changes to the <code class="language-plaintext highlighter-rouge">main</code> branch and ensure the CRuby-specific gems are up to date.</li>
  <li>Merge the <code class="language-plaintext highlighter-rouge">main</code> branch into the <code class="language-plaintext highlighter-rouge">jruby_main</code> branch, adjusting for JRuby-specific gems.</li>
  <li>Resolve any conflicts, especially in the <code class="language-plaintext highlighter-rouge">Gemfile.lock</code>.</li>
  <li>Deploy each branch to separate machines (one for CRuby, one for JRuby).</li>
  <li>Repeat this process for each environment (staging, UAT, production).</li>
</ul>

<p>The need to maintain two separate gem environments and deployment pipelines for CRuby and JRuby added significant complexity.</p>

<h4 id="example-flowchart-pre-upgrade-deployment-process">Example Flowchart: Pre-Upgrade Deployment Process</h4>

<div class="mermaid">
graph TD;
    A[Update main branch] --&gt; B[Merge into jruby_main];
    B --&gt; C[Resolve conflicts in Gemfile.lock];
    C --&gt; D[Deploy to separate environments];
    D --&gt; E[Repeat for each lower environment];
</div>

<p>This workflow not only caused delays but also increased the chance of deployment errors due to conflicts and separate environment management.</p>

<h3 id="post-upgrade-deployment-with-one-branch">Post-Upgrade Deployment with One Branch</h3>

<p>After upgrading to <strong>Ruby 3.2 with YJIT</strong>, the <strong>jruby_main</strong> branch became unnecessary. We could merge everything back into a single branch, reducing the complexity significantly.</p>

<p>Now, we maintain only the <code class="language-plaintext highlighter-rouge">main</code> branch, where all changes are made and tested. With <strong>YJIT</strong> providing the necessary performance improvements, we no longer need separate JRuby optimizations.</p>

<h4 id="post-upgrade-deployment-flow">Post-Upgrade Deployment Flow</h4>

<ul>
  <li>All changes are made in the <code class="language-plaintext highlighter-rouge">main</code> branch.</li>
  <li>No more merging or conflict resolution between branches.</li>
  <li>A single, streamlined deployment process to all environments.</li>
</ul>

<h4 id="example-flowchart-post-upgrade-deployment-process">Example Flowchart: Post-Upgrade Deployment Process</h4>

<div class="mermaid">
graph TD;
    A[Update main branch] --&gt; B[Deploy directly from main];
</div>

<p>This streamlined process has reduced our release times from <strong>60 minutes to just 15 minutes</strong>, eliminating the need to manage multiple branches and environments.</p>

<h2 id="the-ruby-32-upgrade-breaking-changes-and-how-we-tackled-them">The Ruby 3.2 Upgrade: Breaking Changes and How We Tackled Them</h2>

<h3 id="keyword-arguments-are-now-strictly-enforced">Keyword Arguments Are Now Strictly Enforced</h3>

<p>One of the most significant changes in <strong>Ruby 3.2</strong> was the way <strong>keyword arguments</strong> are handled. In Ruby 2.x, keyword arguments could be passed alongside regular arguments, but this flexibility led to bugs and unintended behavior. Ruby 3.2 now requires <strong>strict separation</strong> between positional and keyword arguments.</p>

<h4 id="example-of-keyword-argument-enforcement">Example of Keyword Argument Enforcement</h4>

<p>In Ruby 2.6, the following code would work:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Ruby 2.6 method definition</span>
<span class="k">def</span> <span class="nf">greet</span><span class="p">(</span><span class="nb">name</span><span class="p">:,</span> <span class="n">age</span><span class="p">:)</span>
  <span class="nb">puts</span> <span class="s2">"Hello, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">! You are </span><span class="si">#{</span><span class="n">age</span><span class="si">}</span><span class="s2"> years old."</span>
<span class="k">end</span>

<span class="c1"># In Ruby 2.6, you could do this:</span>
<span class="n">greet</span><span class="p">(</span><span class="ss">name: </span><span class="s2">"Alice"</span><span class="p">,</span> <span class="ss">age: </span><span class="mi">30</span><span class="p">)</span>  <span class="c1"># Works fine</span>
<span class="n">greet</span><span class="p">(</span><span class="ss">name: </span><span class="s2">"Alice"</span><span class="p">,</span> <span class="ss">age: </span><span class="mi">30</span><span class="p">,</span> <span class="ss">city: </span><span class="s2">"New York"</span><span class="p">)</span>  <span class="c1"># No error (extra argument ignored)</span>
</code></pre></div></div>

<p>In <strong>Ruby 3.2</strong>, this would raise an <strong>ArgumentError</strong> because of the extra, unexpected keyword (<code class="language-plaintext highlighter-rouge">city</code>):</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Ruby 3.2 stricter keyword argument handling</span>
<span class="n">greet</span><span class="p">(</span><span class="ss">name: </span><span class="s2">"Alice"</span><span class="p">,</span> <span class="ss">age: </span><span class="mi">30</span><span class="p">)</span>  <span class="c1"># Still works</span>
<span class="n">greet</span><span class="p">(</span><span class="ss">name: </span><span class="s2">"Alice"</span><span class="p">,</span> <span class="ss">age: </span><span class="mi">30</span><span class="p">,</span> <span class="ss">city: </span><span class="s2">"New York"</span><span class="p">)</span>  <span class="c1"># Raises ArgumentError</span>
</code></pre></div></div>

<p>This change forced us to comb through our codebase and ensure every method call and definition had properly specified keywords. We also took this as an opportunity to review our method signatures for better clarity and maintainability.</p>

<h3 id="method-visibility-changes">Method Visibility Changes</h3>

<p>Another notable change was the default visibility for methods defined with <code class="language-plaintext highlighter-rouge">attr_reader</code>, <code class="language-plaintext highlighter-rouge">attr_writer</code>, and <code class="language-plaintext highlighter-rouge">attr_accessor</code>. In Ruby 2.x, these methods were <strong>public</strong> by default, but in <strong>Ruby 3.2</strong>, they are now <strong>private</strong> unless explicitly stated otherwise.</p>

<h4 id="code-example-of-method-visibility-changes">Code Example of Method Visibility Changes</h4>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># In Ruby 2.6, this was public by default</span>
<span class="k">class</span> <span class="nc">Person</span>
  <span class="nb">attr_reader</span> <span class="ss">:name</span>

  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
    <span class="vi">@name</span> <span class="o">=</span> <span class="nb">name</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="c1"># In Ruby 3.2, we need to explicitly make it public</span>
<span class="k">class</span> <span class="nc">Person</span>
  <span class="nb">attr_reader</span> <span class="ss">:name</span>
  <span class="kp">public</span> <span class="ss">:name</span>  <span class="c1"># Make it public manually</span>

  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
    <span class="vi">@name</span> <span class="o">=</span> <span class="nb">name</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h3 id="change-in-postgresql-query-for-datetime-objects">Change in PostgreSQL Query for Datetime Objects</h3>

<p>In <strong>Rails 7</strong>, there was a significant change in how <strong>datetime objects</strong> are handled in <strong>PostgreSQL</strong> queries. Specifically, datetime values that were previously stored in a specific time zone (such as <strong>IST</strong>) are now automatically converted to <strong>UTC</strong> when inserted into the database. This change impacts how time-based data is stored and retrieved, especially for applications dealing with multiple time zones.</p>

<h4 id="example-scenario-event-scheduling">Example Scenario: Event Scheduling</h4>

<p>In <strong>Rails 5</strong>, when an <code class="language-plaintext highlighter-rouge">event_start</code> datetime value was inserted into the database, it would be stored in the local time zone (e.g., <strong>IST</strong>) without conversion. However, in <strong>Rails 7</strong>, the same datetime value is automatically converted to <strong>UTC</strong>, resulting in different behavior when querying and retrieving data.</p>

<h4 id="code-example-before-and-after-rails-7">Code Example: Before and After Rails 7</h4>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Example payload with an event_start datetime in IST</span>
<span class="n">payload</span> <span class="o">=</span> <span class="p">[</span>
  <span class="p">{</span>
    <span class="ss">:event_id</span> <span class="o">=&gt;</span> <span class="mi">1234</span><span class="p">,</span> 
    <span class="ss">:location_id</span> <span class="o">=&gt;</span> <span class="mi">5678</span><span class="p">,</span> 
    <span class="ss">:event_start</span> <span class="o">=&gt;</span> <span class="s2">"2024-04-11T10:55:34.648+05:30"</span>
  <span class="p">}</span>
<span class="p">]</span>

<span class="no">EventList</span><span class="p">.</span><span class="nf">import!</span><span class="p">(</span>
  <span class="n">payload</span><span class="p">,</span>
  <span class="ss">batch_size: </span><span class="no">Settings</span><span class="o">.</span><span class="no">CONSTANTS</span><span class="o">.</span><span class="no">ACTIVE_RECORD</span><span class="o">.</span><span class="no">IMPORT_BATCH_SIZE</span><span class="p">,</span>
  <span class="ss">validate: </span><span class="kp">true</span><span class="p">,</span>
  <span class="ss">on_duplicate_key_update: </span><span class="p">{</span>
    <span class="ss">columns: </span><span class="p">[</span><span class="ss">:event_start</span><span class="p">],</span>
    <span class="ss">conflict_target: </span><span class="p">[</span><span class="ss">:event_id</span><span class="p">]</span>
  <span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div>

<h4 id="pre-upgrade-rails-5-behavior">Pre-Upgrade: Rails 5 Behavior</h4>

<p>In <strong>Rails 5</strong>, when the payload was inserted into the database, the <code class="language-plaintext highlighter-rouge">event_start</code> datetime was stored in <strong>IST</strong> (or the local time zone) without any conversion. The following query illustrates how the datetime was inserted:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">#</span> <span class="n">Rails</span> <span class="mi">5</span><span class="p">:</span> <span class="n">event_start</span> <span class="n">stored</span> <span class="k">as</span> <span class="n">IST</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="nv">"event_lists"</span> 
<span class="p">(</span><span class="nv">"event_id"</span><span class="p">,</span> <span class="nv">"location_id"</span><span class="p">,</span> <span class="nv">"event_start"</span><span class="p">,</span> <span class="nv">"created_at"</span><span class="p">,</span> <span class="nv">"updated_at"</span><span class="p">)</span> 
<span class="k">VALUES</span> 
<span class="p">(</span><span class="mi">1234</span><span class="p">,</span> <span class="mi">5678</span><span class="p">,</span> <span class="s1">'2024-04-11T10:55:34.648+05:30'</span><span class="p">,</span> <span class="s1">'2024-04-11 15:15:55.481787'</span><span class="p">,</span> <span class="s1">'2024-04-11 15:15:55.481787'</span><span class="p">)</span> 
<span class="k">ON</span> <span class="n">CONFLICT</span> <span class="p">(</span><span class="n">event_id</span><span class="p">)</span> 
<span class="k">DO</span> <span class="k">UPDATE</span> 
<span class="k">SET</span> <span class="nv">"event_start"</span> <span class="o">=</span> <span class="n">EXCLUDED</span><span class="p">.</span><span class="nv">"event_start"</span><span class="p">,</span> <span class="nv">"updated_at"</span> <span class="o">=</span> <span class="n">EXCLUDED</span><span class="p">.</span><span class="nv">"updated_at"</span> 
<span class="n">RETURNING</span> <span class="nv">"id"</span><span class="p">;</span>
</code></pre></div></div>

<p>In this case, the <code class="language-plaintext highlighter-rouge">event_start</code> datetime (<code class="language-plaintext highlighter-rouge">2024-04-11T10:55:34.648+05:30</code>) was stored as <strong>IST</strong> without any timezone conversion.</p>

<h4 id="post-upgrade-rails-7-behavior">Post-Upgrade: Rails 7 Behavior</h4>

<p>After upgrading to <strong>Rails 7</strong>, the same <code class="language-plaintext highlighter-rouge">event_start</code> value is automatically converted to <strong>UTC</strong> when inserted into the database. Here‚Äôs what the resulting query looks like:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">#</span> <span class="n">Rails</span> <span class="mi">7</span><span class="p">:</span> <span class="n">event_start</span> <span class="n">automatically</span> <span class="n">converted</span> <span class="k">to</span> <span class="n">UTC</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="nv">"event_lists"</span> 
<span class="p">(</span><span class="nv">"event_id"</span><span class="p">,</span> <span class="nv">"location_id"</span><span class="p">,</span> <span class="nv">"event_start"</span><span class="p">,</span> <span class="nv">"created_at"</span><span class="p">,</span> <span class="nv">"updated_at"</span><span class="p">)</span> 
<span class="k">VALUES</span> 
<span class="p">(</span><span class="mi">1234</span><span class="p">,</span> <span class="mi">5678</span><span class="p">,</span> <span class="s1">'2024-04-11 05:25:34.648000'</span><span class="p">,</span> <span class="s1">'2024-04-11 15:16:23.153978'</span><span class="p">,</span> <span class="s1">'2024-04-11 15:16:23.153978'</span><span class="p">)</span> 
<span class="k">ON</span> <span class="n">CONFLICT</span> <span class="p">(</span><span class="n">event_id</span><span class="p">)</span> 
<span class="k">DO</span> <span class="k">UPDATE</span> 
<span class="k">SET</span> <span class="nv">"event_start"</span> <span class="o">=</span> <span class="n">EXCLUDED</span><span class="p">.</span><span class="nv">"event_start"</span><span class="p">,</span> <span class="nv">"updated_at"</span> <span class="o">=</span> <span class="n">EXCLUDED</span><span class="p">.</span><span class="nv">"updated_at"</span> 
<span class="n">RETURNING</span> <span class="nv">"id"</span><span class="p">;</span>
</code></pre></div></div>

<p>As you can see, the <code class="language-plaintext highlighter-rouge">event_start</code> datetime (<code class="language-plaintext highlighter-rouge">2024-04-11T10:55:34.648+05:30</code>) is now automatically converted to <strong>UTC</strong> (<code class="language-plaintext highlighter-rouge">2024-04-11 05:25:34.648000</code>), reflecting the timezone adjustment.</p>

<h4 id="example-flowchart-datetime-conversion-in-rails-7">Example Flowchart: Datetime Conversion in Rails 7</h4>

<pre><code class="language-mermaid">graph TD;
    A[Datetime in IST: 2024-04-11T10:55:34.648+05:30] --&gt; B[Insert into DB];
    B --&gt; C[Automatically converted to UTC: 2024-04-11 05:25:34.648000];
</code></pre>

<h4 id="impact-of-this-change">Impact of this Change</h4>

<p>This automatic conversion simplifies the handling of datetime fields in the database, ensuring consistency across different time zones. However, it also requires careful handling when generating reports or retrieving data in a specific time zone, as queries may now return <strong>UTC</strong> values. Applications relying on local time zone data will need to adjust by converting <strong>UTC</strong> back to the desired time zone when necessary.</p>

<p>By adapting to this behavior in <strong>Rails 7</strong>, we ensure that our systems handle datetime values more consistently and accurately across various time zones.</p>

<p>This change required careful review of all our model definitions to ensure that method visibility was correctly specified.</p>

<h2 id="rails-706-migration-breaking-changes-and-code-adjustments">Rails 7.0.6 Migration: Breaking Changes and Code Adjustments</h2>

<h3 id="deprecation-of-update_attributes">Deprecation of <code class="language-plaintext highlighter-rouge">update_attributes</code></h3>

<p>Rails 7 deprecates the once-familiar <code class="language-plaintext highlighter-rouge">update_attributes</code> method. Instead, the preferred method is simply <code class="language-plaintext highlighter-rouge">update</code>. While this change was straightforward, it required a thorough search and replace throughout our models.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Before Rails 7</span>
<span class="n">user</span><span class="p">.</span><span class="nf">update_attributes</span><span class="p">(</span><span class="ss">name: </span><span class="s2">"New Name"</span><span class="p">,</span> <span class="ss">email: </span><span class="s2">"newemail@example.com"</span><span class="p">)</span>

<span class="c1"># Rails 7</span>
<span class="n">user</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="ss">name: </span><span class="s2">"New Name"</span><span class="p">,</span> <span class="ss">email: </span><span class="s2">"newemail@example.com"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="return-behavior-in-transactions">Return Behavior in Transactions</h3>

<p>Rails 7 also introduced changes to how <strong>return statements</strong> behave inside transactions. In earlier Rails versions, returning from within a transaction would not necessarily roll it back. However, in <strong>Rails 7</strong>, returning from a transaction block now <strong>rolls back</strong> the entire transaction. This led to some tricky bugs in our payment system where returns were used incorrectly within transactions.</p>

<h3 id="raw-sql-queries-are-no-longer-allowed">Raw SQL Queries Are No Longer Allowed</h3>

<p>Rails 7 deprecated the use of raw SQL queries directly in ActiveRecord, mainly to avoid SQL injection risks. Previously, you could write raw SQL like this:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Before Rails 7, using raw SQL</span>
<span class="no">User</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="s2">"name LIKE ?"</span><span class="p">,</span> <span class="s2">"%John%"</span><span class="p">)</span>
</code></pre></div></div>

<p>In Rails 7, this throws an error. Instead, we now use Rails‚Äô query interface for sanitized queries:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Rails 7 safe query</span>
<span class="no">User</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="s2">"name ILIKE ?"</span><span class="p">,</span> <span class="s2">"%John%"</span><span class="p">)</span>
</code></pre></div></div>

<p>We refactored all occurrences of raw SQL in our codebase to follow Rails‚Äô safer conventions, making our app more secure in the process.</p>

<h3 id="changes-to-update_all">Changes to <code class="language-plaintext highlighter-rouge">update_all</code></h3>

<p>Another subtle but impactful change in Rails 7 was how <code class="language-plaintext highlighter-rouge">update_all</code> works within a transaction. In earlier Rails versions, when <code class="language-plaintext highlighter-rouge">update_all</code> was called, the ActiveRecord objects would not immediately reflect the changes. However, in <strong>Rails 7</strong>, calling <code class="language-plaintext highlighter-rouge">update_all</code> within a transaction updates the objects right away.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Before Rails 7, ActiveRecord object remains unchanged until the transaction completes</span>
<span class="no">User</span><span class="p">.</span><span class="nf">transaction</span> <span class="k">do</span>
  <span class="no">User</span><span class="p">.</span><span class="nf">update_all</span><span class="p">(</span><span class="ss">name: </span><span class="s2">"Updated Name"</span><span class="p">)</span>
  <span class="n">user</span><span class="p">.</span><span class="nf">reload</span>  <span class="c1"># Would still show old name in Rails 5.x</span>
<span class="k">end</span>

<span class="c1"># In Rails 7, update_all changes take effect immediately</span>
<span class="no">User</span><span class="p">.</span><span class="nf">transaction</span> <span class="k">do</span>
  <span class="no">User</span><span class="p">.</span><span class="nf">update_all</span><span class="p">(</span><span class="ss">name: </span><span class="s2">"Updated Name"</span><span class="p">)</span>
  <span class="n">user</span><span class="p">.</span><span class="nf">reload</span>  <span class="c1"># Now shows "Updated Name" immediately</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="migrating-from-octopus-to-rails-6-native-multi-database-support">Migrating from Octopus to Rails 6+ Native Multi-Database Support</h2>

<p>Previously, we were using the <strong>Octopus</strong> gem to manage multi-database configurations. However, <strong>Rails 6</strong> introduced native support for multi-database functionality, making Octopus redundant. The transition to native multi-database support meant we could simplify our <code class="language-plaintext highlighter-rouge">database.yml</code> and remove the Octopus-specific sharding logic.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Old Octopus configuration</span>
<span class="na">development</span><span class="pi">:</span>
  <span class="na">adapter</span><span class="pi">:</span> <span class="s">postgresql</span>
  <span class="na">database</span><span class="pi">:</span> <span class="s">myapp_development</span>
  <span class="na">octopus</span><span class="pi">:</span>
    <span class="na">shards</span><span class="pi">:</span>
      <span class="na">users</span><span class="pi">:</span> <span class="s">myapp_users</span>

<span class="c1"># Rails 6+ native multi-database support</span>
<span class="na">development</span><span class="pi">:</span>
  <span class="na">adapter</span><span class="pi">:</span> <span class="s">postgresql</span>
  <span class="na">database</span><span class="pi">:</span> <span class="s">myapp_development</span>
  <span class="na">users</span><span class="pi">:</span>
    <span class="na">database</span><span class="pi">:</span> <span class="s">myapp_users</span>
</code></pre></div></div>

<p>This was another significant simplification of our infrastructure, reducing the number of external dependencies we relied on.</p>

<h2 id="the-performance-payoff">The Performance Payoff</h2>

<p>After completing these upgrades, we saw <strong>immediate performance improvements</strong> thanks to YJIT. Our CPU usage dropped significantly, and response times for key endpoints improved by up to <strong>30%</strong>. Not to mention, the single-branch deployment process saved us countless hours in deployment overhead.</p>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Prepare for Breaking Changes</strong>: Ruby 3.2 and Rails 7 introduce numerous breaking changes, but they also offer performance and security improvements. It‚Äôs worth the effort to migrate.</li>
  <li><strong>Consolidate Branches</strong>: If you‚Äôre maintaining multiple branches for performance reasons, consider upgrading to Ruby 3.2 with YJIT. It allowed us to merge two branches into one, greatly simplifying our workflow.</li>
  <li><strong>Plan Thoroughly</strong>: Large-scale upgrades require careful planning. Testing in staging environments and refactoring code for keyword arguments, method visibility, and database support is critical to avoid production issues.</li>
</ol>

<h2 id="whats-next">What‚Äôs Next?</h2>

<p>With Ruby 3.2, Rails 7.0.6, and YJIT now powering our app, we‚Äôre well-positioned for future improvements. We‚Äôre already exploring the possibility of integrating <strong>Hotwire</strong> and <strong>Turbo</strong> to further enhance our front-end experience.</p>

<p>If you‚Äôre considering a similar upgrade, my advice is simple: <strong>go for it</strong>. The benefits far outweigh the challenges, and your app will be stronger and faster for it.</p>

<hr />

<p>Thanks for reading! Feel free to reach out if you have any questions about the upgrade process or want to share your own experiences with Ruby and Rails upgrades.</p>

<p>Happy coding!</p>]]></content><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><category term="ruby" /><category term="engineering" /><category term="yjit" /><summary type="html"><![CDATA[Upgrading Ruby and Rails to YJIT: A Deep Dive into Breaking Changes, Challenges, and Code Improvements]]></summary></entry><entry><title type="html">Postgres Sequence Item Go Up Even If Object Creation Fails</title><link href="http://localhost:4000/posts/next_val_postgres/" rel="alternate" type="text/html" title="Postgres Sequence Item Go Up Even If Object Creation Fails" /><published>2024-03-25T00:00:00+00:00</published><updated>2024-03-25T00:00:00+00:00</updated><id>http://localhost:4000/posts/next_val_postgres</id><content type="html" xml:base="http://localhost:4000/posts/next_val_postgres/"><![CDATA[<p>Today while working  on a ror project we run into an abrupt issue wiht transaction where even if the transaction was not being processed the id was increasing leading to a failure in a backgroud sidekiq worker this lead me to this stackover flow post</p>

<p><a href="https://stackoverflow.com/questions/50650010/why-does-postgres-sequence-item-go-up-even-if-object-creation-fails">Post</a>
Which then led me in rabit hole that i have tried to pen to the best of my abilities below :-&gt;</p>

<h1 id="postgresql-sequences-unexpected-increments">PostgreSQL Sequences: Unexpected Increments?</h1>

<p>Imagine you‚Äôre working with a PostgreSQL database, and you‚Äôve set up a sequence to auto-increment primary keys for your <code class="language-plaintext highlighter-rouge">Client</code> model. Everything seems fine until you encounter a puzzling issue: the sequence value jumps up even when a client creation fails.</p>

<h2 id="the-mystery-unveiled">The Mystery Unveiled</h2>

<p>In PostgreSQL, sequences are special objects used to generate unique identifiers, commonly for primary key fields. When you create a new record, PostgreSQL automatically fetches the next value from the sequence and assigns it to the primary key column.</p>

<h3 id="example-scenario">Example Scenario</h3>

<p>Let‚Äôs say your sequence currently stands at 262. You attempt to create a new client, but due to a unique constraint violation (perhaps someone manually set a primary key, which PostgreSQL sequences ignore), the creation fails. Oddly enough, upon rechecking the sequence, you find it‚Äôs incremented to 263, despite no new client being added to the database.</p>

<h3 id="why-does-this-happen">Why Does This Happen?</h3>

<p>PostgreSQL‚Äôs sequence mechanism operates independently of transaction rollbacks. When you call <code class="language-plaintext highlighter-rouge">nextval</code> on a sequence (implicitly done when a new record is inserted), it advances the sequence whether or not the transaction succeeds or fails. This design ensures each session receives a unique sequence value, even if multiple sessions are running concurrently.</p>

<h3 id="consider-the-consequences">Consider the Consequences</h3>

<p>This behavior can lead to unexpected scenarios if not handled carefully. For instance, if your application logic relies on sequential numbering for auditing or reporting purposes, gaps might appear if transactions fail after fetching a sequence value. These gaps are harmless but can be surprising if not anticipated.</p>

<h3 id="best-practices">Best Practices</h3>

<p>To avoid issues:</p>
<ul>
  <li><strong>Avoid Manually Setting Primary Keys:</strong> Let PostgreSQL manage sequence values automatically.</li>
  <li><strong>Handle Unique Constraints Gracefully:</strong> Ensure your application handles unique constraint violations gracefully to prevent unnecessary gaps in sequence usage.</li>
</ul>

<h2 id="visualizing-postgresql-sequence-behavior">Visualizing PostgreSQL Sequence Behavior</h2>

<p>To illustrate, here‚Äôs a table summarizing how PostgreSQL sequences behave:</p>

<table>
  <thead>
    <tr>
      <th>Action</th>
      <th>Sequence Value Before</th>
      <th>Sequence Value After</th>
      <th>Transaction Outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Attempt to Create Client</td>
      <td>262</td>
      <td>262 (if creation fails)</td>
      <td>Transaction fails, no new client added</td>
    </tr>
    <tr>
      <td>Retry Creation</td>
      <td>262</td>
      <td>263 (if creation succeeds)</td>
      <td>Transaction succeeds, new client added</td>
    </tr>
    <tr>
      <td>Query Sequence</td>
      <td>263</td>
      <td>263</td>
      <td>Query reflects latest sequence value</td>
    </tr>
  </tbody>
</table>

<h2 id="conclusion">Conclusion</h2>

<p>Understanding PostgreSQL sequences is crucial for maintaining data integrity and application reliability. While the behavior of sequence incrementation on failed transactions might seem counterintuitive at first, it ensures robustness and scalability in multi-session environments.</p>

<p>So, the next time you encounter an unexpected sequence increment in PostgreSQL, remember: it‚Äôs all part of PostgreSQL‚Äôs design to maintain transactional integrity and support concurrent operations seamlessly.</p>

<p>By grasping these nuances, you can navigate PostgreSQL‚Äôs sequence behavior more effectively, ensuring your applications perform reliably even under challenging conditions. Understanding these mechanics not only enhances your troubleshooting skills but also empowers you to design more resilient database architectures.</p>]]></content><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><category term="Postgres" /><summary type="html"><![CDATA[Today while working on a ror project we run into an abrupt issue wiht transaction where even if the transaction was not being processed the id was increasing leading to a failure in a backgroud sidekiq worker this lead me to this stackover flow post]]></summary></entry><entry><title type="html">1518-Water Bottles</title><link href="http://localhost:4000/posts/leetcode/1518/" rel="alternate" type="text/html" title="1518-Water Bottles" /><published>2022-08-14T00:00:00+01:00</published><updated>2022-08-14T00:00:00+01:00</updated><id>http://localhost:4000/posts/leetcode/water_bottles</id><content type="html" xml:base="http://localhost:4000/posts/leetcode/1518/"><![CDATA[<h2 id="optimized-bottle-exchange">Optimized Bottle Exchange</h2>
<p>Even though this is an easy solution  i absoluetly loved this elegant solution that i thoough of.</p>
<h3 id="approach">Approach</h3>

<p>In this optimized approach, we use math to gulp down as many bottles as possible before exchanging them for full ones. By maximizing each exchange, we ensure efficiency.</p>

<h3 id="steps">Steps</h3>

<ol>
  <li>Start with a count of empty bottles consumed set to zero.</li>
  <li>Continue until the number of full bottles is greater than the exchange rate:
    <ul>
      <li>Calculate the maximum number of full bottles we can gulp down in one go.</li>
      <li>Add these to our consumed count.</li>
      <li>Subtract the corresponding empty bottles from the total.</li>
      <li>Exchange the empty bottles for new full ones.</li>
    </ul>
  </li>
  <li>Return the total number of bottles consumed, including any remaining full bottles.</li>
</ol>

<h3 id="implementation">Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">num_water_bottles</span><span class="p">(</span><span class="n">numBottles</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">numExchange</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="n">consumedBottles</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">numBottles</span> <span class="o">&gt;=</span> <span class="n">numExchange</span><span class="p">:</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">numBottles</span> <span class="o">//</span> <span class="n">numExchange</span>
        <span class="n">consumedBottles</span> <span class="o">+=</span> <span class="n">numExchange</span> <span class="o">*</span> <span class="n">K</span>
        <span class="n">numBottles</span> <span class="o">=</span> <span class="n">numBottles</span> <span class="o">-</span> <span class="n">numExchange</span> <span class="o">*</span> <span class="n">K</span> <span class="o">+</span> <span class="n">K</span>
    <span class="k">return</span> <span class="n">consumedBottles</span> <span class="o">+</span> <span class="n">numBottles</span>
</code></pre></div></div>
<h3 id="complexity">Complexity</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Time: Efficient, logarithmic relative to the number of bottles.
- Space: Minimal, only requires a few variables.
</code></pre></div></div>

<h3 id="question-pattern-resembles">Question Pattern Resembles</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> - Greedy Approach:  You could say it is greedy but i wouldnt classify it as such overall i cant pinpoint it to any particular pattern. 
</code></pre></div></div>

<p>That reminds me Enjoy drinking responsibly and efficiently!</p>]]></content><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><category term="leetcode" /><summary type="html"><![CDATA[Optimized Bottle Exchange Even though this is an easy solution i absoluetly loved this elegant solution that i thoough of. Approach]]></summary></entry><entry><title type="html">Predicting Stock Prices with Sentiment Analysis üìàüòÑ</title><link href="http://localhost:4000/posts/Lstm-Stock/" rel="alternate" type="text/html" title="Predicting Stock Prices with Sentiment Analysis üìàüòÑ" /><published>2022-06-14T00:00:00+01:00</published><updated>2022-06-14T00:00:00+01:00</updated><id>http://localhost:4000/posts/lstm</id><content type="html" xml:base="http://localhost:4000/posts/Lstm-Stock/"><![CDATA[<p>The ideation of this project came from our capstone project under <a href="https://csed.thapar.edu/facultydetails/OTYx">Dr. Seema Bhardwaj</a>. We aimed to create an ML model predictor to help protect my friends from dubious websites and irregular patterns. Simple Stock, the product we developed, focused on prediction and teaching students about stock market trends. This blog deals with the prediction part and our approach to it. If you‚Äôre interested in learning more about the product here is much lengthier <a href="https://drive.google.com/file/d/1-iVwzWASrF0pgtrxj69C8T6OpCDish6C/view?usp=share_link"><code class="language-plaintext highlighter-rouge">breif</code></a> about it .</p>

<p>In this blog post, I‚Äôll take you through one of my exciting data science projects where I used sentiment analysis of news articles to predict stock prices using an LSTM model. Let‚Äôs dive in! üöÄ</p>

<h2 id="introduction">Introduction</h2>

<p>Predicting stock prices is a challenging task due to the numerous factors influencing them. In this project, we will use the VADER sentiment analysis model to analyze news articles and incorporate their sentiment scores as features in our stock price prediction model. Our model will use an LSTM (Long Short-Term Memory) architecture to make predictions based on historical stock prices and news sentiments.</p>

<h2 id="step-by-step-guide">Step-by-Step Guide</h2>

<h3 id="step-1-data-collection-">Step 1: Data Collection üìù</h3>

<p>First, we need to collect historical stock prices and news articles. For this project, I used data from the New York Times and historical stock prices of the top 10 companies in the S&amp;P 500 index.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">yfinance</span> <span class="k">as</span> <span class="n">yf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># List of top 10 S&amp;P 500 companies
</span><span class="n">companies</span> <span class="o">=</span> <span class="p">[</span><span class="s">"AAPL"</span><span class="p">,</span> <span class="s">"MSFT"</span><span class="p">,</span> <span class="s">"AMZN"</span><span class="p">,</span> <span class="s">"GOOGL"</span><span class="p">,</span> <span class="s">"FB"</span><span class="p">,</span> <span class="s">"TSLA"</span><span class="p">,</span> <span class="s">"BRK-B"</span><span class="p">,</span> <span class="s">"JPM"</span><span class="p">,</span> <span class="s">"JNJ"</span><span class="p">,</span> <span class="s">"V"</span><span class="p">]</span>

<span class="c1"># Download historical stock prices
</span><span class="n">stock_data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">company</span> <span class="ow">in</span> <span class="n">companies</span><span class="p">:</span>
    <span class="n">stock_data</span><span class="p">[</span><span class="n">company</span><span class="p">]</span> <span class="o">=</span> <span class="n">yf</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="n">company</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="s">"2015-01-01"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s">"2020-12-31"</span><span class="p">)</span>
    
<span class="c1"># Convert to DataFrame
</span><span class="n">stock_prices</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">stock_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">stock_prices</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">"stock_prices.csv"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="step-2-sentiment-analysis-with-vader-">Step 2: Sentiment Analysis with VADER üòÉüòû</h3>

<p>Next, we‚Äôll use the VADER sentiment analysis model to analyze the sentiment of news articles. VADER is a pre-trained model specifically designed for sentiment analysis of social media texts.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">vaderSentiment.vaderSentiment</span> <span class="kn">import</span> <span class="n">SentimentIntensityAnalyzer</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">analyzer</span> <span class="o">=</span> <span class="n">SentimentIntensityAnalyzer</span><span class="p">()</span>

<span class="c1"># Function to fetch and analyze news sentiment
</span><span class="k">def</span> <span class="nf">fetch_news_sentiment</span><span class="p">(</span><span class="n">company</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"https://api.nytimes.com/svc/search/v2/articlesearch.json?q=</span><span class="si">{</span><span class="n">company</span><span class="si">}</span><span class="s">&amp;api-key=YOUR_API_KEY"</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">articles</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="n">json</span><span class="p">()[</span><span class="s">"response"</span><span class="p">][</span><span class="s">"docs"</span><span class="p">]</span>
    
    <span class="n">sentiments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">articles</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">article</span><span class="p">[</span><span class="s">"lead_paragraph"</span><span class="p">]</span>
        <span class="n">sentiment</span> <span class="o">=</span> <span class="n">analyzer</span><span class="p">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">sentiments</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentiment</span><span class="p">[</span><span class="s">"compound"</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">sentiments</span>

<span class="c1"># Analyze sentiments for each company
</span><span class="n">news_sentiments</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">company</span> <span class="ow">in</span> <span class="n">companies</span><span class="p">:</span>
    <span class="n">news_sentiments</span><span class="p">[</span><span class="n">company</span><span class="p">]</span> <span class="o">=</span> <span class="n">fetch_news_sentiment</span><span class="p">(</span><span class="n">company</span><span class="p">)</span>

<span class="c1"># Convert to DataFrame
</span><span class="n">sentiment_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">news_sentiments</span><span class="p">)</span>
<span class="n">sentiment_df</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">"news_sentiments.csv"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="step-3-data-preparation-">Step 3: Data Preparation üìä</h3>

<p>We need to prepare our data by merging the stock prices and news sentiments. We‚Äôll also normalize the data to ensure consistency.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load data
</span><span class="n">stock_prices</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"stock_prices.csv"</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sentiments</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"news_sentiments.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Normalize stock prices
</span><span class="n">stock_prices_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">stock_prices</span> <span class="o">-</span> <span class="n">stock_prices</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="n">stock_prices</span><span class="p">.</span><span class="n">std</span><span class="p">()</span>

<span class="c1"># Merge data
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">stock_prices_norm</span><span class="p">,</span> <span class="n">sentiments</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="step-4-building-the-lstm-model-">Step 4: Building the LSTM Model üß†</h3>
<p>We‚Äôll build our LSTM model using TensorFlow/Keras. The model will have an input layer, two LSTM layers, and a dense output layer.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Prepare data for LSTM
</span><span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">window_size</span><span class="p">):</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">window_size</span><span class="p">):</span>
        <span class="n">X</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">])</span>
        <span class="n">y</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">window_size</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span>

<span class="c1"># Split data
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Build LSTM model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">window_size</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])),</span>
    <span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'mse'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># Train model
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="step-5-evaluating-the-model-">Step 5: Evaluating the Model üìâ</h3>
<p>We‚Äôll evaluate our model using the Root Mean Squared Error (RMSE) metric to assess its accuracy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="c1"># Predict
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"RMSE: </span><span class="si">{</span><span class="n">rmse</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="conclusion-">Conclusion üéâ</h3>
<p>In this project, we successfully used sentiment analysis of news articles to improve stock price prediction with an LSTM model. By combining historical stock prices and sentiment scores, our model achieved some pretty impressive results. But hey, there‚Äôs always room for improvement! So, don‚Äôt hesitate to experiment with different model architectures and datasets. Happy coding! üòä</p>

<p>Oh, and if you want to check out the initial stages and thought process behind this blog, check out these <a href="https://docs.google.com/presentation/d/1p5pjDrXCANU300sAD91NlZbE9xU09SUX/edit?usp=share_link&amp;ouid=112246221369441046993&amp;rtpof=true&amp;sd=true">slides</a> from back when I was in 3rd year. Do remember, I‚Äôve significantly improved at making presentations‚Äîoops, I mean coding‚Äîsince then!</p>]]></content><author><name>Yash</name><email>yashpathania704@gmail.com</email></author><category term="Lstm" /><category term="DataScience" /><category term="Python" /><summary type="html"><![CDATA[The ideation of this project came from our capstone project under Dr. Seema Bhardwaj. We aimed to create an ML model predictor to help protect my friends from dubious websites and irregular patterns. Simple Stock, the product we developed, focused on prediction and teaching students about stock market trends. This blog deals with the prediction part and our approach to it. If you‚Äôre interested in learning more about the product here is much lengthier breif about it .]]></summary></entry></feed>